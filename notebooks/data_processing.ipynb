{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "from PIL import Image\n",
    "#from skimage.transform import resize\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sony-NEX-7', 'HTC-1-M7', 'Motorola-Droid-Maxx', 'iPhone-6', 'Motorola-Nexus-6', 'Samsung-Galaxy-S4', 'Motorola-X', 'LG-Nexus-5x', 'Samsung-Galaxy-Note3', 'iPhone-4s']\n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "train_path = \"../train/\"\n",
    "test_path = \"../test/\"\n",
    "add_data_path = \"../flickr_images/\"\n",
    "\n",
    "# print mobile models\n",
    "models = os.listdir(train_path)\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping function\n",
    "def center_crop(img_path, new_width, new_height):\n",
    "        im = Image.open(img_path)\n",
    "        width, height = im.size   # Get dimensions\n",
    "        left = (width - new_width)/2\n",
    "        top = (height - new_height)/2\n",
    "        right = (width + new_width)/2\n",
    "        bottom = (height + new_height)/2\n",
    "        result = im.crop((left, top, right, bottom))\n",
    "        return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sony-NEX-7\n",
      "HTC-1-M7\n",
      "Motorola-Droid-Maxx\n",
      "iPhone-6\n",
      "Motorola-Nexus-6\n",
      "Samsung-Galaxy-S4\n",
      "Motorola-X\n",
      "LG-Nexus-5x\n",
      "Samsung-Galaxy-Note3\n",
      "iPhone-4s\n"
     ]
    }
   ],
   "source": [
    "# transform images to 512x512 (cropping from the center)\n",
    "new_width = 512\n",
    "new_height = 512\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "    print(folder)\n",
    "    for pic in os.listdir(train_path + folder + \"/\"):\n",
    "        img_path = train_path + folder + \"/\" + pic\n",
    "        img_cropped = center_crop(img_path, 512, 512)\n",
    "        directory = \"../train_cropped/\" + folder\n",
    "        # create dir if it doesn't exist\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        img_cropped.save(\"../train_cropped/\" + folder + \"/cropped\" + \"_\" + pic )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "def create_if_not_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def create_train_val_test_dir(source, train_perc, val_perc):\n",
    "    # create train, validation and test set\n",
    "    source = \"../train_cropped\"\n",
    "    train_set = \"../train_set\"\n",
    "    val_set = \"../val_set\"\n",
    "    test_set = \"../test_set\"\n",
    "\n",
    "    # create dir if it doesn't exist\n",
    "    for directory in [train_set, val_set, test_set]:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    folders = os.listdir(source)\n",
    "\n",
    "    for f in folders:\n",
    "        val_dir = val_set + '/'+ f + \"/\"\n",
    "        test_dir = test_set + '/'+ f + \"/\"\n",
    "        train_dir = train_set + '/'+ f + \"/\"\n",
    "\n",
    "        create_if_not_exist(val_dir)\n",
    "        create_if_not_exist(test_dir)\n",
    "        create_if_not_exist(train_dir)\n",
    "\n",
    "        for pic in os.listdir(source + \"/\" + f + \"/\"):\n",
    "            rand_num = np.random.rand(1)\n",
    "            if rand_num <= train_perc:\n",
    "                shutil.copy(source + '/'+ f + \"/\" + pic, val_dir)\n",
    "            elif train_perc< rand_num <= train_perc + val_perc:\n",
    "                shutil.copy(source + '/'+ f + \"/\" + pic, test_dir)\n",
    "            else:\n",
    "                shutil.copy(source + '/'+ f + \"/\" + pic, train_dir)\n",
    "            \n",
    "create_train_val_test_dir(train_cropped, 0.2, 0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Experiment\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(512, 512, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation\n",
    "\n",
    "# resizing (via bicubic interpolation) by a factor of 0.5\n",
    "# resizing (via bicubic interpolation) by a factor of 0.8\n",
    "# resizing (via bicubic interpolation) by a factor of 1.5\n",
    "# resizing (via bicubic interpolation) by a factor of 2.0\n",
    "# gamma correction using gamma = 0.8\n",
    "# gamma correction using gamma = 1.2\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1924 images belonging to 10 classes.\n",
      "Found 557 images belonging to 10 classes.\n",
      "Found 269 images belonging to 10 classes.\n",
      "Epoch 1/25\n",
      "4/5 [=======================>......] - ETA: 4s - loss: 2.3142 - acc: 0.0156  "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator( \n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_set,  # this is the target directory\n",
    "        target_size=(512, 512),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_set,\n",
    "        target_size=(512, 512),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_set,\n",
    "        target_size=(512, 512),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=5, # // batch_size,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=20) #00 // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG compression with quality factor = 70\n",
    "# JPEG compression with quality factor = 90\n",
    "def jpeg_compression(img_path, q_factor):\n",
    "    img = Image.open(img_path)\n",
    "    img.save(\"../train_compress_/\" + q_factor + folder + \"/\" + q_factor + \"jpg_\" + pic , \"JPEG\", quality=q_factor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
